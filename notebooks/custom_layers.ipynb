{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invertible Convolution and WaveNet Custom Layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate\n",
    "Start with standard imports as well as adding the scripts directory to the system path to allow custom imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "root_dir, _ = os.path.split(os.getcwd())\n",
    "script_dir = os.path.join(root_dir, 'scripts')\n",
    "sys.path.append(script_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hparams import hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invertible Convolution\n",
    "\n",
    "The training boolean in the call method can be used to run the layer in reverse. This layer is wrapped in tensorflow-addons weight_norm layer in the waveglow initialisation call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inv1x1Conv(layers.Conv1D):\n",
    "  \"\"\"\n",
    "  Tensorflow 2.0 implementation of the inv1x1conv layer \n",
    "  directly subclassing the tensorflow Conv1D layer\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, filters, **kwargs):\n",
    "    super(Inv1x1Conv, self).__init__(\n",
    "      filters=filters,\n",
    "      kernel_size=1,\n",
    "      strides=1,\n",
    "      padding='SAME',\n",
    "      use_bias=False,\n",
    "      kernel_initializer=tf.initializers.orthogonal(),\n",
    "      activation=\"linear\",\n",
    "      **kwargs)\n",
    "  \n",
    "  def call(self, inputs, training=True):\n",
    "    if training:\n",
    "      sign, log_det_weights = tf.linalg.slogdet(\n",
    "        tf.cast(self.kernel, tf.float32))\n",
    "      loss = - tf.cast(tf.reduce_sum(log_det_weights), \n",
    "                       dtype=self.dtype)\n",
    "      self.add_loss(loss)\n",
    "      tf.summary.scalar(name='loss',\n",
    "                       data=loss)\n",
    "      return super(Inv1x1Conv, self).call(inputs)\n",
    "      \n",
    "    else:\n",
    "      if not hasattr(self, 'kernel_inverse'):\n",
    "        self.kernel_inverse = tf.cast(tf.linalg.inv(\n",
    "          tf.cast(self.kernel, tf.float64)), dtype=self.dtype)\n",
    "        \n",
    "      return tf.nn.conv1d(inputs, self.kernel_inverse, \n",
    "                            stride=1, padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nvidia WaveNet Implementation\n",
    "Difference with the original implementations :\n",
    "WaveNet convonlution need not be causal. \n",
    "No dilation size reset. \n",
    "Dilation doubles on each layer\n",
    "\n",
    "It could be worth investigating whether including the weight_norm wrapper of tensorflow addon incurs significant improvements during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNetNvidia(layers.Layer):\n",
    "  \"\"\"\n",
    "  Wavenet Block as defined in the WaveGlow implementation from Nvidia\n",
    "  \n",
    "  WaveNet convonlution need not be causal. \n",
    "  No dilation size reset. \n",
    "  Dilation doubles on each layer.\n",
    "  \"\"\"\n",
    "  def __init__(self, n_in_channels, n_channels = 256, \n",
    "               n_layers = 12, kernel_size = 3, **kwargs):\n",
    "    super(WaveNetNvidia, self).__init__(**kwargs)\n",
    "    \n",
    "    assert(kernel_size % 2 == 1)\n",
    "    assert(n_channels % 2 == 0)\n",
    "    \n",
    "    self.n_layers = n_layers\n",
    "    self.n_channels = n_channels\n",
    "    self.n_in_channels = n_in_channels\n",
    "    self.kernel_size = kernel_size\n",
    "    \n",
    "    self.in_layers = []\n",
    "    self.normalisation_layers = []\n",
    "    self.res_skip_layers = []\n",
    "    self.cond_layers = []\n",
    "    \n",
    "    self.start = layers.Conv1D(filters=self.n_channels,\n",
    "                               kernel_size=1,\n",
    "                               dtype=self.dtype,\n",
    "                               name=\"start\")\n",
    "\n",
    "    self.end = layers.Conv1D(\n",
    "      filters=2 * self.n_in_channels,\n",
    "      kernel_size = 1,\n",
    "      kernel_initializer=tf.initializers.zeros(),\n",
    "      bias_initializer=tf.initializers.zeros(),\n",
    "      dtype=self.dtype,\n",
    "      name=\"end\")\n",
    "\n",
    "    for index in range(self.n_layers):\n",
    "      dilation_rate = 2 ** index\n",
    "      in_layer = layers.Conv1D(filters=2 * self.n_channels,\n",
    "                    kernel_size= self.kernel_size,\n",
    "                    dilation_rate=dilation_rate,\n",
    "                    padding=\"SAME\",\n",
    "                    dtype=self.dtype,\n",
    "                    name=\"conv1D_{}\".format(index))\n",
    "      \n",
    "      self.normalisation_layers.append(\n",
    "        layers.BatchNormalization())\n",
    "     \n",
    "      # Nvidia has a weight_norm func here, training stability?\n",
    "      # Memory expensive in implementation of tf-addons wrapper\n",
    "      self.in_layers.append(in_layer)\n",
    "      \n",
    "      \n",
    "      cond_layer = layers.Conv1D(filters = 2 * self.n_channels,\n",
    "                                 kernel_size = 1,\n",
    "                                 padding=\"SAME\",\n",
    "                                 dtype=self.dtype,\n",
    "                                 name=\"cond_{}\".format(index))\n",
    "      self.cond_layers.append(cond_layer)\n",
    "      \n",
    "      if index < self.n_layers - 1:\n",
    "        res_skip_channels = 2 * self.n_channels\n",
    "      else:\n",
    "        res_skip_channels = self.n_channels\n",
    "        \n",
    "      res_skip_layer = layers.Conv1D(\n",
    "        filters=res_skip_channels,\n",
    "        kernel_size=1,\n",
    "        dtype=self.dtype,\n",
    "        name=\"res_skip_{}\".format(index))\n",
    "      \n",
    "      self.res_skip_layers.append(res_skip_layer)\n",
    "      \n",
    "    \n",
    "  def call(self, inputs):\n",
    "    \"\"\"\n",
    "    This implementatation does not require exposing a training boolean flag \n",
    "    as only the affine coupling behaviour needs reversing during\n",
    "    inference.\n",
    "    \"\"\"\n",
    "    audio_0, spect = inputs\n",
    "    \n",
    "    started = self.start (audio_0)   \n",
    "    \n",
    "    for index in range(self.n_layers):\n",
    "      in_layered = self.in_layers[index](started)\n",
    "      self.normalisation_layers[index]()\n",
    "      \n",
    "      cond_layered = self.cond_layers[index](spect)\n",
    "      \n",
    "      half_tanh, half_sigmoid = tf.split(\n",
    "        in_layered + cond_layered, 2, axis=2)\n",
    "      half_tanh = tf.nn.tanh(half_tanh)\n",
    "      half_sigmoid = tf.nn.sigmoid(half_sigmoid)\n",
    "    \n",
    "      activated = half_tanh * half_sigmoid\n",
    "      \n",
    "      res_skip_activation = self.res_skip_layers[index](activated)\n",
    "      \n",
    "      if index < (self.n_layers - 1):\n",
    "        res_skip_activation_0, res_skip_activation_1 = tf.split(\n",
    "          res_skip_activation, 2, axis=2)\n",
    "        started = res_skip_activation_0 + started\n",
    "        skip_activation = res_skip_activation_1\n",
    "      else:\n",
    "        skip_activation = res_skip_activation\n",
    "\n",
    "      if index == 0:\n",
    "        output = skip_activation\n",
    "      else:\n",
    "        output = skip_activation + output\n",
    "        \n",
    "    output = self.end(output)\n",
    "    \n",
    "    log_s, bias = tf.split(output, 2, axis=2)\n",
    "    \n",
    "    return output\n",
    "  \n",
    "  def get_config(self):\n",
    "    config = super(WaveNetBlock, self).get_config()\n",
    "    config.update(n_in_channels = self.n_in_channels)\n",
    "    config.update(n_channels = self.n_channels)\n",
    "    config.update(n_layers = self.n_layers)\n",
    "    config.update(kernel_size = self.kernel_size)\n",
    "  \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Affine Coupling Layer\n",
    "\n",
    "This layer does not have any trainable weights. It can be inverted by setting the training boolean to false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineCoupling(layers.Layer):\n",
    "  \"\"\"\n",
    "  Invertible Affine Layer\n",
    "  \n",
    "  The inverted behaviour is obtained by setting the training boolean\n",
    "  in the call method to false\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, **kwargs):\n",
    "    super(AffineCoupling, self).__init__(**kwargs)\n",
    "    \n",
    "  def call(self, inputs, training=None):\n",
    "    \n",
    "    audio_1, wavenet_output = inputs\n",
    "    \n",
    "    log_s, bias = tf.split(wavenet_output, 2, axis=2)\n",
    "    \n",
    "    if training:\n",
    "      audio_1 = audio_1 * tf.math.exp(log_s) + bias\n",
    "      loss = - tf.reduce_sum(log_s)\n",
    "      self.add_loss(loss)\n",
    "      tf.summary.scalar(name='loss', data=loss)\n",
    "    else:\n",
    "      audio_1 = (audio_1 - bias) *  tf.math.exp( - log_s)      \n",
    "    \n",
    "    return audio_1\n",
    "  \n",
    "  def get_config(self):\n",
    "    config = super(AffineCoupling, self).get_config()\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaveNet And Affine Coupling\n",
    "This block is a convenience block which has been defined to make it more straightforward to implement the WaveGlow model using the keras functional API. Note that affine coupling is the choice made in the original implementation of WaveGlow, but other choices are possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNetAffineBlock(layers.Layer):\n",
    "  \"\"\"\n",
    "  Wavenet + Affine Layer\n",
    "  Convenience block to provide a tidy model definition\n",
    "  \"\"\"\n",
    "  def __init__(self, n_in_channels, n_channels = 256,\n",
    "               n_layers = 12, kernel_size = 3, **kwargs):\n",
    "    super(WaveNetAffineBlock, self).__init__(**kwargs)\n",
    "    \n",
    "    self.n_layers =  n_layers\n",
    "    self.n_channels = n_channels\n",
    "    self.n_in_channels = n_in_channels\n",
    "    self.kernel_size = kernel_size\n",
    "    \n",
    "    self.wavenet = WaveNetNvidia(n_in_channels=n_in_channels,\n",
    "                                 n_channels=n_channels,\n",
    "                                 n_layers=n_layers,\n",
    "                                 kernel_size=kernel_size,\n",
    "                                 dtype=self.dtype)\n",
    "    \n",
    "    self.affine_coupling = AffineCoupling(dtype=self.dtype)\n",
    "      \n",
    "    \n",
    "  def call(self, inputs, training=None):\n",
    "    \"\"\"\n",
    "    training should be set to false to inverse affine layer\n",
    "    \"\"\"\n",
    "    audio, spect = inputs\n",
    "    audio_0, audio_1 = tf.split(audio, 2, axis=2)\n",
    "    \n",
    "    wavenet_output = self.wavenet((audio_0, spect))\n",
    "    \n",
    "    audio_1 = self.affine_coupling(\n",
    "      (audio_1, wavenet_output), training=training)   \n",
    "         \n",
    "    audio = layers.Concatenate(\n",
    "      axis=2, \n",
    "      dtype=self.wavenet.dtype) ([audio_0, audio_1])\n",
    "    \n",
    "    return audio\n",
    "  \n",
    "  def get_config(self):\n",
    "    config = super(WaveNetBlock, self).get_config()\n",
    "    config.update(n_in_channels = self.n_in_channels)\n",
    "    config.update(n_channels = self.n_channels)\n",
    "    config.update(n_layers = self.n_layers)\n",
    "    config.update(kernel_size = self.kernel_size)\n",
    "  \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Implementation of WeightNormalisedInvertible1x1Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inv1x1ConvWeightNorm(layers.Conv1D):\n",
    "  \n",
    "  \n",
    "  def __init__(self, filters, **kwargs):\n",
    "    super(Inv1x1ConvWeightNorm, self).__init__(\n",
    "      filters=filters,\n",
    "      kernel_size=1,\n",
    "      strides=1,\n",
    "      padding='SAME',\n",
    "      use_bias=False,\n",
    "      kernel_initializer=tf.initializers.orthogonal(),\n",
    "      activation=\"linear\",\n",
    "      **kwargs)\n",
    "    self._initialized = False\n",
    "    self._kernel_updated = False\n",
    "    \n",
    "  def build(self, input_shape):\n",
    "    super(Inv1x1ConvWeightNorm, self).build(input_shape)\n",
    "    self._kernel_updated = True\n",
    "    \n",
    "    self.layer_depth = self.filters\n",
    "    self.kernel_norm_axes = [0, 1]\n",
    "      \n",
    "    self.v = self.kernel\n",
    "    self.kernel_inverse = self.kernel\n",
    "    self.g = self.add_weight(\n",
    "        name=\"g\",\n",
    "        shape=self.layer_depth,\n",
    "        initializer=tf.keras.initializers.get('ones'),\n",
    "        dtype=self.dtype,\n",
    "        trainable=True)\n",
    "    \n",
    "    flat = tf.squeeze(self.v, axis=0)\n",
    "    self.g.assign(tf.linalg.norm(flat, axis=0))\n",
    "  \n",
    "  \n",
    "  def call(self, inputs, training=True):\n",
    "    if training:\n",
    "      g = tf.identity(self.g)\n",
    "      \n",
    "      self.kernel = tf.nn.l2_normalize(\n",
    "        self.v, axis=self.kernel_norm_axes) * g\n",
    "      \n",
    "      sign, log_det_weights = tf.linalg.slogdet(\n",
    "        tf.cast(self.kernel, tf.float32))\n",
    "      loss = - tf.cast(tf.reduce_sum(log_det_weights), \n",
    "                       dtype=self.dtype)\n",
    "      self.add_loss(loss)\n",
    "      tf.summary.scalar(name='loss',\n",
    "                       data=loss)\n",
    "      return super(Inv1x1ConvWeightNorm, self).call(inputs)\n",
    "      \n",
    "    else:\n",
    "      # if not hasattr(self, 'kernel_inverse'):\n",
    "      if self._kernel_updated:\n",
    "        self.kernel_inverse = tf.cast(tf.linalg.inv(\n",
    "          tf.cast(self.kernel, tf.float32)), dtype=self.dtype)\n",
    "        self._kernel_updated = False\n",
    "        \n",
    "      return tf.nn.conv1d(inputs, self.kernel_inverse, \n",
    "                            stride=1, padding='SAME')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2rc",
   "language": "python",
   "name": "tf2rc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
