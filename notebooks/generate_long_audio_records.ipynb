{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Long Audio Sample records file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "root_dir, _ = os.path.split(os.getcwd())\n",
    "script_dir = os.path.join(root_dir, 'scripts')\n",
    "sys.path.append(script_dir)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# tf.keras.backend.set_floatx('float16')\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hparams import hparams\n",
    "from waveglow_model import WaveGlow\n",
    "import training_utils as utils\n",
    "import random\n",
    "import pathlib\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load long samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_orig = tf.keras.utils.get_file(origin='https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2',\n",
    "                                         fname='LJSpeech-1.1', untar=True, cache_dir=hparams['data_dir'])\n",
    "\n",
    "data_root = pathlib.Path(data_root_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_root = pathlib.Path(hparams['data_dir'])\n",
    "all_sound_paths = list(data_root.glob('*/*'))\n",
    "all_sound_paths = [str(path) for path in all_sound_paths]\n",
    "\n",
    "random.seed(a=1234)\n",
    "random.shuffle(all_sound_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_preprocess_wav_file(sound_path, hparams):\n",
    "    '''\n",
    "    Read wav file and compute mel spectrogram\n",
    "    '''\n",
    "    sound = tf.io.read_file(sound_path)\n",
    "    signal = tf.squeeze(tf.audio.decode_wav(sound).audio)\n",
    "    number_of_slices = math.floor(signal.shape[0] / hparams['segment_length'])\n",
    "    sound_tensors = [signal[i*hparams['segment_length']:(i+1)*hparams['segment_length']] for i in range(0, number_of_slices - 1)]\n",
    "\n",
    "    mels = compute_mel_spectrograms(sound_tensors, hparams)\n",
    "    \n",
    "    sound_tensors = [tf.cast(sound_tensor, dtype=hparams['ftype']) for sound_tensor in sound_tensors]\n",
    "    mels = [tf.cast(mel, dtype=hparams['ftype']) for mel in mels]\n",
    "    \n",
    "    return [dict(wav=sound_tensor, mel=mel, path=sound_path, number_of_slices=number_of_slices) for sound_tensor, mel in zip(sound_tensors, mels)]\n",
    "  \n",
    "def compute_mel_spectrograms(sound_tensors, hparams):\n",
    "  '''\n",
    "  Compute mel spectrogram from all sound tensors\n",
    "  '''\n",
    "  mels = []\n",
    "  for sound_tensor in sound_tensors:\n",
    "    stft = tf.signal.stft(sound_tensor,\n",
    "                          frame_length=hparams['fft_size'],\n",
    "                          frame_step=hparams['hop_size'],\n",
    "                          fft_length=hparams['fft_size'],\n",
    "                          pad_end=True)\n",
    "\n",
    "    magnitude = tf.abs(stft)\n",
    "\n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "      hparams['mel_channels'], \n",
    "      magnitude.shape[-1],\n",
    "      hparams['sample_rate'], \n",
    "      hparams['fmin'],\n",
    "      hparams['fmax'])\n",
    "\n",
    "    # Mel Spectrogram\n",
    "    mel = tf.tensordot(magnitude, linear_to_mel_weight_matrix, 1)\n",
    "    mel = tf.math.log(tf.maximum(mel, 1e-5)) # log scaling with clamping\n",
    "    mel = tf.cast(mel, dtype=hparams['ftype'])\n",
    "    mels.append(mel)\n",
    "\n",
    "  return mels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize function and proto tf.Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sound_example(features, hparams):\n",
    "  '''\n",
    "  Creates a tf.Example message from wav, mel\n",
    "  ''' \n",
    "  \n",
    "  features = {\n",
    "    \"wav\": _bytes_feature(tf.io.serialize_tensor(features['wav'])),\n",
    "    \"mel\": _bytes_feature(tf.io.serialize_tensor(features['mel'])),\n",
    "    \"path\": _bytes_feature(tf.io.serialize_tensor(features['path'])),\n",
    "    \"number_of_slices\": _bytes_feature(tf.io.serialize_tensor(features['number_of_slices']))\n",
    "  }\n",
    "\n",
    "  return tf.train.Example(\n",
    "      features=tf.train.Features(feature=features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ds = iter(tf.data.Dataset.from_tensor_slices(all_sound_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_tfrecords_writer(path_ds, record_file, n_samples, hparams):\n",
    "    with tf.io.TFRecordWriter(record_file) as writer:\n",
    "        for path, sample in zip(path_ds, range(n_samples)):\n",
    "            features = split_and_preprocess_wav_file(path, hparams)\n",
    "            for feature in features:\n",
    "              tf_example = sound_example(features=feature, hparams=hparams)\n",
    "              writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_file = os.path.join(hparams['tfrecords_dir'], hparams['long_audio_file'])\n",
    "sample = 30\n",
    "single_tfrecords_writer(path_ds, record_file, sample, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waveglow-gpu",
   "language": "python",
   "name": "waveglow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
