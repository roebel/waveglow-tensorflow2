{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waveglow parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of flow blocks/composite layers in the model. Each flow is Invertible Convolution + Affine Coupling Layer to Wavenet\n",
    "hparams['n_flows'] = 12\n",
    "# Number of initial channels in invertible convolution\n",
    "hparams['n_group'] = 8\n",
    "# Number of flow layers between each channel reduction\n",
    "hparams['n_early_every'] = 4\n",
    "# Number of channels to shave from audio sample every n_early_every\n",
    "hparams['n_early_size'] = 2\n",
    "# Upsamplig scale of the mel spectrogram\n",
    "hparams['upsampling_size'] = 256 \n",
    "# Gaussian mixture standard deviation\n",
    "hparams['sigma'] = 1.0\n",
    "# Hidden Channels\n",
    "hparams[\"hidden_channels\"] = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavenet Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of composite layer in Wavenet acting first with separate Conv1D on audio and spectrogram\n",
    "# followed by sigmoid and tanh activations. Last comes a skip_layer\n",
    "hparams['n_layers'] = 8\n",
    "# Kernel size of the Wavenet convolution, no causality restriction\n",
    "hparams['kernel_size'] = 3\n",
    "# Number of hidden channels in Wavenet composite layers\n",
    "hparams['n_channels'] = 256\n",
    "# Only half of the audio sample channels go through wavenet. Other half will be conditioned by its result \n",
    "# via affine coupling layer\n",
    "hparams['n_in_channels'] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of audio samples from LJSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window of the short-time Fourier transform\n",
    "hparams['fft_size'] = 1024\n",
    "# Window shift of the short-time Fourier transform\n",
    "hparams['hop_size'] = 256\n",
    "# Crop audio samples to length 16000 (~5-10% of original)\n",
    "hparams['segment_length'] = 16000\n",
    "# Number of band in mel_spectrum. Becomes number of channel for spectrogram\n",
    "hparams['mel_channels'] = 80\n",
    "# Wav file sampling rate\n",
    "hparams['sample_rate'] = 22050\n",
    "# Cut-off frequencies for the fast Fourier transform\n",
    "hparams['fmin'] = 0.0\n",
    "hparams['fmax'] = 8000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machinery Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floating precision. Float16 is not supported on cpus\n",
    "hparams['ftype'] = tf.float32\n",
    "# Batch size for training\n",
    "hparams['train_batch_size'] = 24\n",
    "# Learning rate, set to range(1e-3, 1e-4) for Adam and 1.0 for AdaDelta. Learning rate scheduler not supported yet\n",
    "hparams['learning_rate'] = 3e-4\n",
    "# Number of epochs to iterate over. Might be replaced by a number of training step in the future\n",
    "hparams['epochs'] = 200\n",
    "# Buffer size for shuffling\n",
    "hparams['buffer_size'] = 24\n",
    "# Optimizer, either Adam or AdaDelta. If AdaDelta, learning_rate = 1.0. \n",
    "# Added experimental tensorflow wrapper to support tf.float16\n",
    "hparams['optimizer'] = \"Adam\" \n",
    "# Enable mixed precision calculation\n",
    "hparams['mixed_precision'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model every number of step\n",
    "hparams['save_model_every'] = 250\n",
    "# Save audio samples every number of step\n",
    "hparams['save_audio_every'] = 1000\n",
    "# Number of checkpoint files to keep\n",
    "hparams['max_to_keep'] = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tfrecords files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data in n_shards tfrecords files\n",
    "hparams['n_shards'] = 12 \n",
    "# Number of excluded example from training set to generate audio samples at each epochs for quality assessment\n",
    "hparams['n_eval_samples'] = 20 \n",
    "# Number of audio samples to run\n",
    "hparams['n_test_samples'] = 80\n",
    "# Training tfrecords common filename\n",
    "hparams['train_files'] = 'ljs_train'\n",
    "# Evaluation tfrecords filename\n",
    "hparams['eval_file'] = 'ljs_eval.tfrecords'\n",
    "# Test tfrecords filename\n",
    "hparams['test_file'] = 'ljs_test.tfrecords'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data directory\n",
    "hparams['data_dir'] = \"/home/phd/.keras/datasets/LJSpeech-1.1\"\n",
    "# Tfrecords directory. Use different directories for float32 and float16 to avoid rerun of preprocessing\n",
    "hparams['tfrecords_dir'] = \"/home/phd/Projects/waveglow-tensorflow2/data/float32/\"\n",
    "# Log directory for tf.summary and tensorboard\n",
    "hparams['log_dir'] = \"/home/phd/Projects/waveglow-tensorflow2/logs/test/mixed_precision_day\"\n",
    "# Checkpoint directory to save and restore model\n",
    "hparams['checkpoint_dir'] = \"/home/phd/Projects/waveglow-tensorflow2/checkpoints/test/mixed_precision_day\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legacy or Not implemented\n",
    "# Not sure if it is used anywhere, I think it is equivalent the number of channels in Wavenet\n",
    "# hparams['train_steps'] = 100  # Not implemented"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2rc",
   "language": "python",
   "name": "tf2rc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
