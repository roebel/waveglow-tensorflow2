{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "root_dir, _ = os.path.split(os.getcwd())\n",
    "script_dir = os.path.join(root_dir, 'scripts')\n",
    "sys.path.append(script_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hparams import hparams\n",
    "from custom_layers import Inv1x1Conv, WaveNetAffineBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveGlow(tf.keras.Model):\n",
    "  \"\"\"\n",
    "  Waveglow implementation using the Invertible1x1Conv custom layer and \n",
    "  the WaveNet custom block \n",
    "  Likely change to have a hyperparameter dict\n",
    "  The init function needs to be adjusted as we don't need to specify\n",
    "  input dimension here as far as I understand the new 2.0 standards\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, hparams, **kwargs):\n",
    "    super(WaveGlow, self).__init__(dtype=hparams['ftype'], **kwargs)\n",
    "    \n",
    "    assert(hparams['n_group'] % 2 == 0)\n",
    "    self.n_flows = hparams['n_flows']\n",
    "    self.n_group = hparams['n_group']\n",
    "    self.n_early_every = hparams['n_early_every']\n",
    "    self.n_early_size = hparams['n_early_size']\n",
    "    self.upsampling_size = hparams['upsampling_size']\n",
    "    self.hidden_channels = hparams['hidden_channels']\n",
    "    self.mel_channels = hparams['mel_channels']\n",
    "    self.hparams = hparams\n",
    "    self.normalisation = self.hparams['train_batch_size'] * self.hparams['segment_length']\n",
    "\n",
    "    self.waveNetAffineBlocks = []\n",
    "    self.weightNormInv1x1ConvLayers = []\n",
    "    \n",
    "    self.upsampling = layers.UpSampling1D(size=self.upsampling_size,\n",
    "                                          dtype=self.dtype)\n",
    "      \n",
    "    n_half = self.n_group // 2\n",
    "    n_remaining_channels = self.n_group\n",
    "    \n",
    "    for index in range(self.n_flows):\n",
    "      if ((index % self.n_early_every == 0) and (index > 0)):\n",
    "        n_half -= self.n_early_size // 2\n",
    "        n_remaining_channels -= self.n_early_size\n",
    "        \n",
    "    \n",
    "      self.weightNormInv1x1ConvLayers.append(\n",
    "        tfa.layers.wrappers.WeightNormalization(\n",
    "          Inv1x1Conv(\n",
    "            filters=n_remaining_channels,\n",
    "            dtype=hparams['ftype'],\n",
    "            name=\"newInv1x1conv_{}\".format(index)),\n",
    "          data_init=False,\n",
    "          dtype=hparams['ftype']))\n",
    "      \n",
    "      self.waveNetAffineBlocks.append(\n",
    "        WaveNetAffineBlock(n_in_channels=n_half, \n",
    "                     n_channels=hparams['n_channels'],\n",
    "                     n_layers=hparams['n_layers'],\n",
    "                     kernel_size=hparams['kernel_size'],\n",
    "                     dtype=hparams['ftype'],\n",
    "                     name=\"waveNetAffineBlock_{}\".format(index)))\n",
    "      \n",
    "    self.n_remaining_channels = n_remaining_channels\n",
    "    \n",
    "    \n",
    "  def call(self, inputs, training=None):\n",
    "    \"\"\"\n",
    "    Evaluate model against inputs\n",
    "    \n",
    "    if training is false simply return the output of the infer method,\n",
    "    which effectively run through the layers backward and invert them.\n",
    "    Otherwise run the network in the training \"direction\".\n",
    "    \"\"\"\n",
    "    \n",
    "    if not training:\n",
    "      return self.infer(inputs)\n",
    "    \n",
    "    audio, spect = inputs['wav'], inputs['mel']\n",
    "    \n",
    "    audio = layers.Reshape(\n",
    "      target_shape = [self.hparams[\"segment_length\"] // self.n_group,\n",
    "                      self.n_group],\n",
    "      dtype=self.dtype) (audio)\n",
    "    \n",
    "    # No reshape happening here, but enforce well defined rank\n",
    "    # for spect tensor which is required for upsampling layer\n",
    "    spect = layers.Reshape(\n",
    "      target_shape = [63, self.mel_channels],\n",
    "      dtype=self.dtype) (spect)\n",
    "    \n",
    "    spect = self.upsampling(spect)\n",
    "    \n",
    "    spect = layers.Cropping1D(\n",
    "      cropping=(0, spect.shape[1] - hparams['segment_length']),\n",
    "      dtype=self.dtype) (spect)\n",
    "\n",
    "    spect = layers.Reshape(\n",
    "      [self.hparams[\"segment_length\"] // self.n_group, \n",
    "       self.mel_channels * self.n_group],\n",
    "      dtype=self.dtype) (spect)\n",
    "    \n",
    "    output_audio = []\n",
    "    n_remaining_channels = self.n_group\n",
    "    \n",
    "    for index in range(self.n_flows):\n",
    "      if ((index % self.n_early_every == 0) and (index > 0)):\n",
    "        n_remaining_channels -= hparams['n_early_size']\n",
    "        \n",
    "        audio = layers.Permute(dims=(2, 1), dtype=self.dtype) (audio)\n",
    "        output_chunk = layers.Cropping1D(\n",
    "          cropping=(0, n_remaining_channels),\n",
    "          dtype=self.dtype) (audio)\n",
    "        audio = layers.Cropping1D(\n",
    "          cropping=(hparams['n_early_size'], 0),\n",
    "          dtype=self.dtype) (audio)\n",
    "        audio = layers.Permute(dims=(2, 1), dtype=self.dtype) (audio)\n",
    "        output_chunk = layers.Permute(dims=(2, 1), \n",
    "                                      dtype=self.dtype) (output_chunk)\n",
    "        output_audio.append(output_chunk)\n",
    "        \n",
    "        # output_audio.append(audio[:, :, :self.n_early_size])\n",
    "        # audio = audio[:,:,self.n_early_size:]\n",
    "        \n",
    "      # No need to output log_det_W or log_s as added as loss in custom \n",
    "      # layers \n",
    "      audio = self.weightNormInv1x1ConvLayers[index](audio)\n",
    "      audio = self.waveNetAffineBlocks[index]((audio, spect),\n",
    "                                              training=True)     \n",
    "      \n",
    "    output_audio.append(audio)\n",
    "    self.custom_logging()\n",
    "    \n",
    "    return layers.Concatenate(axis=2, dtype=self.dtype) (output_audio)\n",
    "  \n",
    "  def infer(self, spect, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Push inputs through network in reverse direction.\n",
    "    Two key aspects:\n",
    "    Layers in reverse order.\n",
    "    Layers are inverted through exposed training boolean.\n",
    "    \"\"\"\n",
    "\n",
    "    spect = layers.Reshape(\n",
    "      target_shape=[63,\n",
    "                    self.hparams['mel_channels']]) (spect)\n",
    "    \n",
    "    spect = self.upsampling(spect)\n",
    "    spect = layers.Cropping1D(\n",
    "      cropping=(0, spect.shape[1] - self.hparams['segment_length'])) (spect)\n",
    "    \n",
    "    spect = layers.Reshape(\n",
    "      [self.hparams[\"segment_length\"] // self.n_group, \n",
    "       self.mel_channels * self.n_group]) (spect)\n",
    "    \n",
    "    audio = tf.random.normal(\n",
    "      shape = [spect.shape[0],\n",
    "               self.hparams['segment_length'] // self.n_group, \n",
    "               self.n_remaining_channels],\n",
    "      dtype = self.hparams['ftype'])\n",
    "\n",
    "    audio *= sigma\n",
    "    \n",
    "    for index in reversed(range(self.n_flows)):\n",
    "      \n",
    "      audio = self.waveNetAffineBlocks[index] ((audio, spect),\n",
    "                                               training=False)\n",
    "      \n",
    "      audio = self.weightNormInv1x1ConvLayers[index](audio, training=False)\n",
    "      \n",
    "      if ((index % self.n_early_every == 0) and (index > 0)):\n",
    "        z = tf.random.normal(\n",
    "          shape = [spect.shape[0],\n",
    "                   self.hparams['segment_length'] // self.n_group, \n",
    "                   self.n_early_size],\n",
    "          dtype = self.hparams['ftype'])\n",
    "        audio = layers.Concatenate(axis=2)([z * sigma, audio])\n",
    "        \n",
    "    audio = layers.Reshape(\n",
    "      target_shape=[self.hparams['segment_length']]) (audio)\n",
    "        \n",
    "    return audio\n",
    "  \n",
    "  def get_config(self):\n",
    "    config = super(WaveGlow, self).get_config()\n",
    "    config.update(hparams = hparams)\n",
    "    \n",
    "    return config\n",
    "  \n",
    "  def custom_logging(self):\n",
    "    \n",
    "    invconv_loss = tf.math.accumulate_n(\n",
    "      [layer.losses[0] for layer in self.weightNormInv1x1ConvLayers])\n",
    "    affine_loss =  tf.math.accumulate_n(\n",
    "      [layer.losses[0] for layer in self.waveNetAffineBlocks])\n",
    "    \n",
    "    tf.summary.scalar(name='invertible_layers_aggregated',\n",
    "                      data=invconv_loss / self.n_group)\n",
    "    tf.summary.scalar(name='wavenet_layers_aggregated',\n",
    "                      data= (affine_loss / self.normalisation))\n",
    "\n",
    "    for index in range(self.n_flows):\n",
    "      tf.summary.scalar(\n",
    "        name='flow_{}'.format(index),\n",
    "        data=self.weightNormInv1x1ConvLayers[index].losses[0] +\\\n",
    "          (self.waveNetAffineBlocks[index].losses[0]/self.normalisation))\n",
    "      \n",
    "      tf.summary.scalar(\n",
    "        name='AffineNormalized_{}'.format(index),\n",
    "        data=self.waveNetAffineBlocks[index].losses[0]/self.normalisation)\n",
    "      \n",
    "      tf.summary.scalar(\n",
    "        name='inv1x1convNormalized_{}'.format(index),\n",
    "        data=self.weightNormInv1x1ConvLayers[index].losses[0]/self.n_group)\n",
    "      \n",
    "  \n",
    "  def total_loss(self, outputs):\n",
    "  \n",
    "    outputs_loss = tf.reduce_sum(outputs * outputs) \\\n",
    "      / (2 * self.hparams['sigma'] * self.hparams['sigma'])\n",
    "\n",
    "    affine_loss =  tf.math.accumulate_n(\n",
    "      [layer.losses[0] for layer in self.waveNetAffineBlocks])\n",
    "    invconv_loss =  tf.math.accumulate_n(\n",
    "      [layer.losses[0] for layer in self.weightNormInv1x1ConvLayers])\n",
    "\n",
    "    total_loss = (outputs_loss + affine_loss) / self.normalisation\n",
    "    total_loss += (invconv_loss / self.n_group)\n",
    "\n",
    "    tf.summary.scalar(name='total_loss',\n",
    "                      data=total_loss)\n",
    "  \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
