{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Long Audio  Sample from trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "root_dir, _ = os.path.split(os.getcwd())\n",
    "script_dir = os.path.join(root_dir, 'scripts')\n",
    "sys.path.append(script_dir)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "# tf.keras.backend.set_floatx('float16')\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hparams import hparams\n",
    "from waveglow_model import WaveGlow\n",
    "import training_utils as utils\n",
    "import random\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_audio = False\n",
    "save_audio = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Long Audio Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = utils.load_single_file_tfrecords(\n",
    "  record_file=os.path.join(hparams['tfrecords_dir'], hparams['test_file']))\n",
    "test_dataset = test_dataset.batch(\n",
    "  hparams['train_batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load long samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_orig = tf.keras.utils.get_file(origin='https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2',\n",
    "                                         fname='LJSpeech-1.1', untar=True, cache_dir=hparams['data_dir'])\n",
    "data_root = pathlib.Path(data_root_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_root = pathlib.Path(hparams['data_dir'])\n",
    "all_sound_paths = list(data_root.glob('*/*'))\n",
    "all_sound_paths = [str(path) for path in all_sound_paths]\n",
    "\n",
    "random.seed(a=1234)\n",
    "random.shuffle(all_sound_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed long audio split mel spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_audio_record_file = os.path.join(hparams['tfrecords_dir'], hparams['long_audio_file'])\n",
    "long_audio_dataset = utils.load_long_audio_tfrecords(long_audio_record_file).batch(hparams['train_batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myWaveGlow = WaveGlow(hparams=hparams, name='myWaveGlow')\n",
    "optimizer = utils.get_optimizer(hparams=hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Checkpoints : Initialise or Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from /home/victor/Projects/Github/waveglow-tensorflow2/checkpoints/float32/run2_batch12_Adam\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(0), \n",
    "                                 optimizer=optimizer, \n",
    "                                 net=myWaveGlow)\n",
    "\n",
    "manager_checkpoint = tf.train.CheckpointManager(\n",
    "  checkpoint, \n",
    "  directory=hparams['checkpoint_dir'],\n",
    "  max_to_keep=hparams['max_to_keep'])\n",
    "\n",
    "checkpoint.restore(manager_checkpoint.latest_checkpoint)\n",
    "\n",
    "if manager_checkpoint.latest_checkpoint:\n",
    "  tf.print('Restored from {checkpoint_dir}'.format(**hparams))\n",
    "else:\n",
    "  raise ValueError('Fetch a valid checkpoint!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/victor/miniconda3/envs/waveglow-gpu/lib/python3.7/site-packages/tensorflow_addons/layers/wrappers.py:84: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "batched_long_audios = []\n",
    "for x_train in long_audio_dataset:\n",
    "  batched_long_audios.append(myWaveGlow.infer(x_train['mel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = dict()\n",
    "originals = dict()\n",
    "\n",
    "for x_train, samples in zip(long_audio_dataset, batched_long_audios):\n",
    "  splits = tf.unique_with_counts(x_train['path'])\n",
    "  long_audios = [audio for audio in tf.split(samples, splits.count)]\n",
    "  for index, path in enumerate(splits.y.numpy()):\n",
    "    if path.decode('utf-8') in audios.keys():\n",
    "      audios[path.decode('utf-8')] = tf.concat([audios[path.decode('utf-8')], tf.reshape(long_audios[index], [-1])], axis=0)\n",
    "    else:\n",
    "      audios[path.decode('utf-8')] = tf.reshape(long_audios[index], [-1]) \n",
    "      signal = tf.io.read_file(path)\n",
    "      original = np.squeeze(tf.audio.decode_wav(signal).audio.numpy())\n",
    "      originals[path.decode('utf-8')] = original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_audio:\n",
    "  for original, audio in zip(originals.values(), audios.values()):\n",
    "    print('original')\n",
    "    ipd.display(ipd.Audio(original[:audio.shape[0]], rate=hparams['sample_rate']))\n",
    "    print('generated')\n",
    "    ipd.display(ipd.Audio(audio, rate=hparams['sample_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ028-0333.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ035-0133.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ048-0240.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ043-0105.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ004-0237.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ038-0103.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ026-0125.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ032-0117.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ037-0081.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ035-0178.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ018-0097.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ043-0019.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ048-0018.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ036-0205.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ033-0164.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ045-0201.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ006-0126.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ035-0030.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ023-0007.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ016-0229.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ043-0125.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ014-0078.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ016-0130.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ018-0375.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ014-0096.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ035-0034.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ006-0083.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ027-0045.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ004-0114.wav\n",
      "/tmp/.keras/datasets/LJSpeech-1.1/wavs/LJ035-0153.wav\n"
     ]
    }
   ],
   "source": [
    "if save_audio:\n",
    "  for (path, original), audio in zip(originals.items(), audios.values()):\n",
    "    print(path)\n",
    "    _ , name = os.path.split(path)\n",
    "    original_wav = tf.audio.encode_wav(tf.expand_dims(original[:audio.shape[0]], axis=1), sample_rate=hparams['sample_rate'])\n",
    "    tf.io.write_file(filename=os.path.join(os.getcwd(), '..', 'data', 'audio_samples', 'original_' + name), contents=original_wav)\n",
    "    audio_wav = tf.audio.encode_wav(tf.expand_dims(audio, axis=1), sample_rate=hparams['sample_rate'])\n",
    "    tf.io.write_file(filename=os.path.join(os.getcwd(), '..', 'data', 'audio_samples', 'generated_' + name), contents=audio_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waveglow-gpu",
   "language": "python",
   "name": "waveglow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
