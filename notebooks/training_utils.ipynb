{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions (needs refactoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "root_dir, _ = os.path.split(os.getcwd())\n",
    "script_dir = os.path.join(root_dir, 'scripts')\n",
    "sys.path.append(script_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hparams import hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_feature_description = {\n",
    "  \"wav\": tf.io.FixedLenFeature([], tf.string),\n",
    "  \"mel\": tf.io.FixedLenFeature([], tf.string)\n",
    "}\n",
    "\n",
    "def _parse_sound_function(example_proto):\n",
    "  x = tf.io.parse_single_example(example_proto, sound_feature_description)\n",
    "  x['wav'] = tf.io.parse_tensor(x['wav'], out_type=hparams['ftype'])\n",
    "  x['mel'] = tf.io.parse_tensor(x['mel'], out_type=hparams['ftype'])  \n",
    "  return x\n",
    "\n",
    "long_sound_feature_description = {\n",
    "  \"wav\": tf.io.FixedLenFeature([], tf.string),\n",
    "  \"mel\": tf.io.FixedLenFeature([], tf.string),\n",
    "  \"path\": tf.io.FixedLenFeature([], tf.string),\n",
    "  \"number_of_slices\": tf.io.FixedLenFeature([], tf.string)\n",
    "}\n",
    "\n",
    "def _parse_long_sound_function(example_proto):\n",
    "  x = tf.io.parse_single_example(example_proto, long_sound_feature_description)\n",
    "  x['wav'] = tf.io.parse_tensor(x['wav'], out_type=hparams['ftype'])\n",
    "  x['mel'] = tf.io.parse_tensor(x['mel'], out_type=hparams['ftype'])\n",
    "  x['path'] = tf.io.parse_tensor(x['path'], out_type=tf.string)\n",
    "  x['number_of_slices'] = tf.io.parse_tensor(x['number_of_slices'], out_type=tf.int32)  \n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_file_tfrecords(record_file):\n",
    "  raw_sound_dataset = tf.data.TFRecordDataset(record_file)\n",
    "  parsed_sound_dataset = raw_sound_dataset.map(_parse_sound_function)\n",
    "  return parsed_sound_dataset\n",
    "\n",
    "def load_long_audio_tfrecords(record_file):\n",
    "  raw_sound_dataset = tf.data.TFRecordDataset(record_file)\n",
    "  parsed_sound_dataset = raw_sound_dataset.map(_parse_long_sound_function)\n",
    "  return parsed_sound_dataset\n",
    "\n",
    "def load_training_files_tfrecords(record_pattern):\n",
    "  record_files = tf.data.TFRecordDataset.list_files(\n",
    "    file_pattern=record_pattern)\n",
    "  raw_sound_dataset = record_files.interleave(\n",
    "    tf.data.TFRecordDataset,\n",
    "    cycle_length=1,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  parsed_sound_dataset = raw_sound_dataset.map(\n",
    "    _parse_sound_function,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  \n",
    "  training_dataset = parsed_sound_dataset.shuffle(\n",
    "    buffer_size=hparams['buffer_size']).batch(\n",
    "    hparams['train_batch_size'],\n",
    "    drop_remainder=True).prefetch(\n",
    "    buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "  \n",
    "  return training_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(eval_dataset, waveGlow, hparams, step):\n",
    "  if tf.equal(step, 0):\n",
    "    for sample, x in eval_dataset.enumerate():\n",
    "      x['wav'] = tf.cast(x['wav'], dtype=tf.float32)\n",
    "      tf.summary.audio(name='original_{}'.format(sample),\n",
    "                       data=tf.expand_dims(x['wav'], axis=2),\n",
    "                       sample_rate=hparams['sample_rate'],\n",
    "                       max_outputs=hparams['train_batch_size'],\n",
    "                       encoding='wav',\n",
    "                       step=step)\n",
    "    tf.summary.text(name='hparams',\n",
    "                    data=pprint.pformat(hparams),\n",
    "                    step=step)\n",
    "    tf.summary.text(name=\"checkpoint_restore\",\n",
    "                    data=\"Initializing from scratch.\",\n",
    "                    step=step)\n",
    "  else:\n",
    "    for sample, x in eval_dataset.enumerate():\n",
    "      eval_samples = waveGlow.infer(x['mel'])\n",
    "      eval_samples = tf.cast(eval_samples, dtype=tf.float32)\n",
    "      tf.summary.audio(name='generated_{}_at_{}'.format(sample, step),\n",
    "                       data=tf.expand_dims(eval_samples, axis=2),\n",
    "                       sample_rate=hparams['sample_rate'],\n",
    "                       max_outputs=hparams['train_batch_size'],\n",
    "                       encoding='wav',\n",
    "                       step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer compatibility with tf.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(hparams):\n",
    "  \"\"\"\n",
    "  Return optimizer instance based on hparams\n",
    "  \n",
    "  Wrap the optimizer to avoid underflow if ftype=tf.float16\n",
    "  \"\"\"\n",
    "  if hparams['optimizer'] == \"Adam\":\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "      learning_rate=hparams[\"learning_rate\"])\n",
    "  elif hparams['optimizer'] == \"Adadelta\":\n",
    "    assert(hparams[\"learning_rate\"] == 1.0), \"Set learning_rate to 1.0\"\n",
    "    optimizer = tf.keras.optimizers.Adadelta(\n",
    "      learning_rate=hparams['learning_rate'])\n",
    "  else:\n",
    "    raise ValueError(\"Supported Optimizer is either Adam or Adagrad\")\n",
    "    \n",
    "  if hparams[\"mixed_precision\"]:\n",
    "    return tf.train.experimental.enable_mixed_precision_graph_rewrite(\n",
    "      optimizer, \"dynamic\")\n",
    "  else:\n",
    "    return optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
